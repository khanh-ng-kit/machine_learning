{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69fcb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORT THƯ VIỆN\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Layer, Flatten,Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b391e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1. TẠO OUTPUT & LOG \n",
    "output_dir = 'output_rbf'\n",
    "os.makedirs(output_dir,exist_ok=True)\n",
    "\n",
    "log_file = open(os.path.join(output_dir,'log_output.txt'),'w')\n",
    "sys.stdout = log_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CHUẨN BỊ DỮ LIỆU: CHIA DATASET THÀNH TRAIN, VAL, TEST VÀ THỐNG KÊ\n",
    "original_data_dir = r'/kaggle/input/dataset/datasetriceleaf'  # Thư mục gốc chứa ảnh theo lớp\n",
    "base_dir = 'rice_data_rbf_split'  # Thư mục mới để chứa dữ liệu chia sẵn\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "class_counts = {}  # Lưu số lượng ảnh theo lớp trước chia tách\n",
    "\n",
    "# Liệt kê tên các lớp và đếm số lượng ảnh\n",
    "class_names = []\n",
    "for cls in os.listdir(original_data_dir):\n",
    "    cls_path = os.path.join(original_data_dir, cls)\n",
    "    if os.path.isdir(cls_path):\n",
    "        imgs = os.listdir(cls_path)\n",
    "        class_counts[cls] = len(imgs)\n",
    "        class_names.append(cls)\n",
    "print(\"Cac lop trong du lieu:\")\n",
    "for cls in sorted(class_names):\n",
    "    print(f\"- {cls}\")\n",
    "\n",
    "#Xóa thư mục chia cũ\n",
    "if os.path.exists(base_dir):\n",
    "    print(\"Dang xoa thu muc cu de chia lai...\")\n",
    "    shutil.rmtree(base_dir)\n",
    "\n",
    "# Tạo lại thư mục chia dữ liệu\n",
    "os.makedirs(train_dir)\n",
    "os.makedirs(val_dir)\n",
    "os.makedirs(test_dir)\n",
    "\n",
    "\n",
    "#CHIA DỮ LIỆU\n",
    "for cls in class_counts.keys():\n",
    "    imgs = os.listdir(os.path.join(original_data_dir, cls))\n",
    "    random.shuffle(imgs)\n",
    "    n_total = len(imgs)\n",
    "    n_train = int(n_total * 0.8)\n",
    "    n_val = int(n_total * 0.1)\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        src = os.path.join(original_data_dir, cls, img)\n",
    "        if i < n_train:\n",
    "            dst = os.path.join(train_dir, cls)\n",
    "        elif i < n_train + n_val:\n",
    "            dst = os.path.join(val_dir, cls)\n",
    "        else:\n",
    "            dst = os.path.join(test_dir, cls)\n",
    "        os.makedirs(dst, exist_ok=True)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "#Nén thư mục chia \n",
    "shutil.make_archive('rice_data_rbf_split', 'zip', base_dir)\n",
    "print(\"Da nen du lieu thanh file rice_data_rbf_split.zip, ban co the tai xuong file nay\")\n",
    "\n",
    "#THỐNG KÊ SỐ LƯỢNG ẢNH SAU KHI CHIA\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\nThong ke so anh trong tap {split}:\")\n",
    "    split_path = os.path.join(base_dir, split)\n",
    "    if os.path.exists(split_path):\n",
    "        for cls in os.listdir(split_path):\n",
    "            cls_path = os.path.join(split_path, cls)\n",
    "            if os.path.isdir(cls_path):\n",
    "                n = len(os.listdir(cls_path))\n",
    "                print(f\"- {cls}: {n} anh\")\n",
    "    else:\n",
    "        print(f\"Thu muc {split_path} khong ton tai.\")\n",
    "\n",
    "#KIỂM TRA THƯ MỤC ---\n",
    "print(\"\\nKiem tra ton tai thu muc:\")\n",
    "print(\"bas dir ton tai:\", os.path.exists(base_dir))\n",
    "print(\"Train dir ton tai:\", os.path.exists(train_dir))\n",
    "print(\"Val dir ton tai:\", os.path.exists(val_dir))\n",
    "print(\"Test dir ton tai:\", os.path.exists(test_dir))\n",
    "\n",
    "# VẼ BIỂU ĐỒ PHÂN BỐ SỐ LƯỢNG ẢNH BAN ĐẦU THEO LỚP\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))\n",
    "plt.title('So luong anh theo lop (truoc khi chia)')\n",
    "plt.xlabel('Lop benh')\n",
    "plt.ylabel('So luong anh')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir,'initial_class_distribution.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. TIỀN XỬ LÝ DỮ LIỆU\n",
    "img_size = (64, 64)\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "#Lưu class_indices\n",
    "class_indices = train_gen.class_indices\n",
    "with open (os.path.join(output_dir,'class_indices.json'),'w') as f:\n",
    "    json.dump(class_indices,f)\n",
    "print(\"Đã lưu file class_indices.json.\")\n",
    "\n",
    "val_gen = val_test_datagen.flow_from_directory(val_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical')\n",
    "test_gen = val_test_datagen.flow_from_directory(test_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical', shuffle=False)\n",
    "\n",
    "num_classes = train_gen.num_classes\n",
    "input_shape = (img_size[0], img_size[1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CHUẨN BỊ TẬP DỮ LIỆU PHẲNG\n",
    "def get_flattened_features(generator):\n",
    "    features, labels = [], []\n",
    "    for i in range(len(generator)):\n",
    "        x, y = generator[i]  #Trả về 1 batch dữ liệu; x: batch ảnh,shape(batch_size, height, width, 3); y: batch nhãn, shape:(batch_size, num_classes)\n",
    "        features.append(x)   #Lưu batch ảnh\n",
    "        labels.append(y)     #Lưu batch nhãn\n",
    "    #Gộp toàn bộ batch lại thành: \n",
    "    X = np.concatenate(features) #X:shape(total_shape, height, width, 3)\n",
    "    y = np.concatenate(labels)   #Y:shape(total_sample, num_classes)\n",
    "    return X.reshape(X.shape[0], -1), y #Làm phẳng ảnh từ 3D thành 1D- X.shape[0]:số ảnh;-1: tự suy ra số chiều còn lại= height*width*3\n",
    "\n",
    "X_train_flat, y_train = get_flattened_features(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e4255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. TÌM CENTER BẰNG KMEANS\n",
    "n_centers = 300  # Giữ nguyên số lượng centers hoặc có thể điều chỉnh\n",
    "kmeans = KMeans(n_clusters=n_centers, random_state=42)\n",
    "kmeans.fit(X_train_flat)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# 5.1 Tính beta riêng cho từng center\n",
    "def calculate_per_center_beta(centers, k=5):\n",
    "    \"\"\"\n",
    "    Tính beta riêng cho từng center dựa trên khoảng cách đến k center gần nhất\n",
    "    \n",
    "    Args:\n",
    "        centers: Ma trận các centers từ KMeans\n",
    "        k: Số lượng centers lân cận để tính sigma\n",
    "    \n",
    "    Returns:\n",
    "        Mảng beta tương ứng cho từng center\n",
    "    \"\"\"\n",
    "    betas = np.zeros(len(centers))\n",
    "    dist_matrix = cdist(centers, centers, metric='euclidean')\n",
    "    \n",
    "    for i in range(len(centers)):\n",
    "        # Lấy khoảng cách từ center i đến các center khác (đã sắp xếp)\n",
    "        dists = np.sort(dist_matrix[i])\n",
    "        # Bỏ qua chính nó (khoảng cách = 0) và lấy k center gần nhất\n",
    "        sigma = np.mean(dists[1:k+1])  # dists[0] luôn là 0 (khoảng cách đến chính nó)\n",
    "        betas[i] = 1.0 / (2 * (sigma ** 2))\n",
    "    \n",
    "    return betas\n",
    "\n",
    "# Tính beta cho từng center (thử với k=5 lân cận)\n",
    "betas = calculate_per_center_beta(centers, k=5)\n",
    "print(f\"Beta values per center - Min: {np.min(betas):.6f}, Max: {np.max(betas):.6f}, Mean: {np.mean(betas):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a2626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. XÂY DỰNG LỚP RBF ĐỂ HỖ TRỢ BETA RIÊNG CHO TỪNG CENTER\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, centers, betas, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.centers_np = centers if isinstance(centers, np.ndarray) else np.array(centers)\n",
    "        self.betas_np = betas if isinstance(betas, np.ndarray) else np.array(betas)\n",
    "        \n",
    "        # Chuyển sang tensor\n",
    "        self.centers = tf.constant(self.centers_np, dtype=tf.float32)\n",
    "        self.betas = tf.constant(self.betas_np, dtype=tf.float32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        inputs = tf.reshape(inputs, [tf.shape(inputs)[0], -1])  # Flatten đầu vào\n",
    "        C = tf.expand_dims(self.centers, 0)  # shape: [1, num_centers, features]\n",
    "        X = tf.expand_dims(inputs, 1)        # shape: [batch_size, 1, features]\n",
    "        \n",
    "        # Tính khoảng cách Euclid\n",
    "        squared_diff = tf.square(X - C)\n",
    "        dist = tf.reduce_sum(squared_diff, axis=-1)  # shape: [batch_size, num_centers]\n",
    "        \n",
    "        # Áp dụng beta riêng cho từng center\n",
    "        rbf_output = tf.exp(-tf.multiply(self.betas, dist))\n",
    "        return rbf_output\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"centers\": self.centers_np.tolist(),\n",
    "            \"betas\": self.betas_np.tolist(),\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. XÂY DỰNG MÔ HÌNH RBF \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "inputs = Input(shape=(64,64,3))\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "x = Flatten()(inputs)\n",
    "x = RBFLayer(centers, betas=betas)(x)  # Sử dụng betas riêng cho từng center\n",
    "x = BatchNormalization()(x)  # Thêm BatchNorm để ổn định\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.001))(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# 8. CALLBACKS\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True,\n",
    "        mode='min'\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(output_dir, 'best_model.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    TensorBoard(\n",
    "        log_dir=os.path.join(output_dir, 'logs'),\n",
    "        histogram_freq=1,\n",
    "        update_freq='epoch'\n",
    "    )\n",
    "]\n",
    "# 9. HUẤN LUYỆN MÔ HÌNH\n",
    "epochs = 100\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=len(val_gen),\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1. Lưu model\n",
    "model.save(\"/kaggle/working/rice_leaf_rbf_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. ĐÁNH GIÁ\n",
    "test_gen.reset()\n",
    "pred = model.predict(test_gen)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_true = test_gen.classes\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=test_gen.class_indices.keys()))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=test_gen.class_indices.keys(), yticklabels=test_gen.class_indices.keys(), cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir,'confusion_matrix.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfafce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. BIỂU ĐỒ ACCURACY VÀ LOSS\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy theo tung epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir,'accuracy_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss theo tung epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'loss_plot.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bfff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. ĐÓNG FILE LOG VÀ KHÔI PHỤC STDOUT\n",
    "sys.stdout = sys.__stdout__\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e19e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. ZIP FOLDER OUTPUT\n",
    "shutil.make_archive(\"output_rbf\",'zip',output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hocmay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
